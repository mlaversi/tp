{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Text_Gen1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJpUakuOZ9Fr"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "In this example we will train a model using the poem \"The Raven\", by Edgar Allan Poe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "844a7c30-97af-45bd-8025-fa90c6b62448"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"Once upon a midnight dreary, while I pondered, weak and weary, \\n Over many a quaint and curious volume of forgotten lore— \\nWhile I nodded, nearly napping, suddenly there came a tapping, \\n As of some one gently rapping, rapping at my chamber door. \\nTis some visitor, I muttered, tapping at my chamber door— \\nOnly this and nothing more. \\nAh, distinctly I remember it was in the bleak December; \\nAnd each separate dying ember wrought its ghost upon the floor. \\nEagerly I wished the morrow;—vainly I had sought to borrow \\nFrom my books surcease of sorrow—sorrow for the lost Lenore— \\nFor the rare and radiant maiden whom the angels name Lenore—\\nNameless here for evermore. \\nAnd the silken, sad, uncertain rustling of each purple curtain\\nThrilled me—filled me with fantastic terrors never felt before;\\n    So that now, to still the beating of my heart, I stood repeating\\n    ’Tis some visitor entreating entrance at my chamber door—\\nSome late visitor entreating entrance at my chamber door;—\\n            This it is and nothing more.\\n    Presently my soul grew stronger; hesitating then no longer,\\nSir, said I, or Madam, truly your forgiveness I implore;\\n   But the fact is I was napping, and so gently you came rapping,\\n   And so faintly you came tapping, tapping at my chamber door,\\nThat I scarce was sure I heard you—here I opened wide the door;—\\n            Darkness there and nothing more.\\n    Deep into that darkness peering, long I stood there wondering, fearing,\\nDoubting, dreaming dreams no mortal ever dared to dream before;\\n    But the silence was unbroken, and the stillness gave no token,\\n    And the only word there spoken was the whispered word, Lenore?\\nThis I whispered, and an echo murmured back the word, Lenore!—\\n           Merely this and nothing more.\\n    Back into the chamber turning, all my soul within me burning,\\nSoon again I heard a tapping somewhat louder than before.\\n    Surely, said I, surely that is something at my window lattice;\\n     Let me see, then, what thereat is, and this mystery explore—\\nLet my heart be still a moment and this mystery explore;—\\n            ’Tis the wind and nothing more!\\n    Open here I flung the shutter, when, with many a flirt and flutter,\\nIn there stepped a stately Raven of the saintly days of yore;\\n    Not the least obeisance made he; not a minute stopped or stayed he;\\n    But, with mien of lord or lady, perched above my chamber door—\\nPerched upon a bust of Pallas just above my chamber door—\\n            Perched, and sat, and nothing more.\\nThen this ebony bird beguiling my sad fancy into smiling,\\nBy the grave and stern decorum of the countenance it wore,\\nThough thy crest be shorn and shaven, thou, I said, art sure no craven,\\nGhastly grim and ancient Raven wandering from the Nightly shore—\\nTell me what thy lordly name is on the Night’s Plutonian shore!\\n            Quoth the Raven Nevermore.\\n    Much I marvelled this ungainly fowl to hear discourse so plainly,\\nThough its answer little meaning—little relevancy bore;\\n   For we cannot help agreeing that no living human being\\n    Ever yet was blessed with seeing bird above his chamber door—\\nBird or beast upon the sculptured bust above his chamber door,\\n            With such name as Nevermore.\\n    But the Raven, sitting lonely on the placid bust, spoke only\\nThat one word, as if his soul in that one word he did outpour.\\n    Nothing farther then he uttered—not a feather then he fluttered—\\n    Till I scarcely more than muttered Other friends have flown before—\\nOn the morrow he will leave me, as my Hopes have flown before.\\n            Then the bird said Nevermore.\\n    Startled at the stillness broken by reply so aptly spoken,\\nDoubtless, said I, what it utters is its only stock and store\\n    Caught from some unhappy master whom unmerciful Disaster\\n    Followed fast and followed faster till his songs one burden bore—\\nTill the dirges of his Hope that melancholy burden bore\\n           Of ‘Never—nevermore’.\\n    But the Raven still beguiling all my fancy into smiling,\\nStraight I wheeled a cushioned seat in front of bird, and bust and door;\\n    Then, upon the velvet sinking, I betook myself to linking\\n    Fancy unto fancy, thinking what this ominous bird of yore—\\nWhat this grim, ungainly, ghastly, gaunt, and ominous bird of yore\\n            Meant in croaking Nevermore.\\n   This I sat engaged in guessing, but no syllable expressing\\nTo the fowl whose fiery eyes now burned into my bosom’s core;\\n    This and more I sat divining, with my head at ease reclining\\n    On the cushion’s velvet lining that the lamp-light gloated o’er,\\nBut whose velvet-violet lining with the lamp-light gloating o’er,\\n           She shall press, ah, nevermore!\\n    Then, methought, the air grew denser, perfumed from an unseen censer\\nSwung by Seraphim whose foot-falls tinkled on the tufted floor.\\n    Wretch, I cried, thy God hath lent thee—by these angels he hath sent thee\\n   Respite—respite and nepenthe from thy memories of Lenore;\\nQuaff, oh quaff this kind nepenthe and forget this lost Lenore!\\n           Quoth the Raven Nevermore.\\n    Prophet! said I, thing of evil!—prophet still, if bird or devil!—\\nWhether Tempter sent, or whether tempest tossed thee here ashore,\\n   Desolate yet all undaunted, on this desert land enchanted—\\n   On this home by Horror haunted—tell me truly, I implore—\\nIs there—is there balm in Gilead?—tell me—tell me, I implore!\\n            Quoth the Raven Nevermore.\\n    Prophet! said I, thing of evil!—prophet still, if bird or devil!\\nBy that Heaven that bends above us—by that God we both adore—\\n    Tell this soul with sorrow laden if, within the distant Aidenn,\\n    It shall clasp a sainted maiden whom the angels name Lenore—\\nClasp a rare and radiant maiden whom the angels name Lenore.\\n           Quoth the Raven Nevermore.\\n   Be that word our sign of parting, bird or fiend! I shrieked, upstarting—\\nGet thee back into the tempest and the Night’s Plutonian shore!\\n    Leave no black plume as a token of that lie thy soul hath spoken!\\n    Leave my loneliness unbroken!—quit the bust above my door!\\nTake thy beak from out my heart, and take thy form from off my door!\\n            Quoth the Raven Nevermore.\\n    And the Raven, never flitting, still is sitting, still is sitting\\nOn the pallid bust of Pallas just above my chamber door;\\n    And his eyes have all the seeming of a demon’s that is dreaming,\\n    And the lamp-light o’er him streaming throws his shadow on the floor;\\nAnd my soul from out that shadow that lies floating on the floor\\n            Shall be lifted—nevermore!\\n\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'i': 3, 'my': 4, 'of': 5, 'this': 6, 'that': 7, 'a': 8, 'chamber': 9, 'is': 10, 'raven': 11, 'bird': 12, 'on': 13, 'door': 14, 'nevermore': 15, 'at': 16, 'more': 17, 'from': 18, 'with': 19, 'then': 20, 'or': 21, 'nothing': 22, 'in': 23, 'me': 24, 'still': 25, 'no': 26, 'said': 27, 'but': 28, 'he': 29, 'above': 30, 'thy': 31, 'his': 32, 'there': 33, 'was': 34, 'to': 35, 'soul': 36, 'into': 37, 'word': 38, 'bust': 39, 'upon': 40, 'tapping': 41, 'as': 42, 'some': 43, 'door—': 44, 'it': 45, 'name': 46, 'so': 47, '—': 48, 'lenore': 49, 'what': 50, 'by': 51, 'quoth': 52, 'one': 53, 'only': 54, 'floor': 55, 'for': 56, 'whom': 57, 'angels': 58, 'before': 59, 'all': 60, 'be': 61, 'fancy': 62, 'if': 63, 'came': 64, 'rapping': 65, 'visitor': 66, 'its': 67, 'lenore—': 68, 'maiden': 69, 'here': 70, 'heart': 71, 'spoken': 72, 'back': 73, 'perched': 74, 'sat': 75, 'sitting': 76, 'till': 77, 'have': 78, 'leave': 79, 'velvet': 80, 'whose': 81, 'lamp': 82, 'light': 83, 'o’er': 84, 'shall': 85, 'hath': 86, 'thee': 87, 'while': 88, 'many': 89, 'napping': 90, 'gently': 91, 'muttered': 92, 'ah': 93, 'each': 94, 'morrow': 95, 'lost': 96, 'rare': 97, 'radiant': 98, 'sad': 99, 'never': 100, 'now': 101, 'stood': 102, '’tis': 103, 'entreating': 104, 'entrance': 105, 'grew': 106, 'truly': 107, 'implore': 108, 'you': 109, 'sure': 110, 'heard': 111, 'darkness': 112, 'dreaming': 113, 'ever': 114, 'unbroken': 115, 'stillness': 116, 'token': 117, 'whispered': 118, 'an': 119, 'within': 120, 'than': 121, 'surely': 122, 'let': 123, 'mystery': 124, 'yore': 125, 'not': 126, 'pallas': 127, 'just': 128, 'beguiling': 129, 'smiling': 130, 'though': 131, 'ghastly': 132, 'grim': 133, 'tell': 134, 'night’s': 135, 'plutonian': 136, 'shore': 137, 'ungainly': 138, 'fowl': 139, 'bore': 140, 'we': 141, 'yet': 142, 'flown': 143, 'followed': 144, 'burden': 145, 'ominous': 146, 'eyes': 147, 'lining': 148, 'god': 149, 'sent': 150, 'nepenthe': 151, 'quaff': 152, 'prophet': 153, 'thing': 154, 'evil': 155, '—prophet': 156, 'devil': 157, 'whether': 158, 'tempest': 159, 'clasp': 160, 'take': 161, 'out': 162, 'shadow': 163, 'once': 164, 'midnight': 165, 'dreary': 166, 'pondered': 167, 'weak': 168, 'weary': 169, 'over': 170, 'quaint': 171, 'curious': 172, 'volume': 173, 'forgotten': 174, 'lore—': 175, 'nodded': 176, 'nearly': 177, 'suddenly': 178, 'tis': 179, 'distinctly': 180, 'remember': 181, 'bleak': 182, 'december': 183, 'separate': 184, 'dying': 185, 'ember': 186, 'wrought': 187, 'ghost': 188, 'eagerly': 189, 'wished': 190, '—vainly': 191, 'had': 192, 'sought': 193, 'borrow': 194, 'books': 195, 'surcease': 196, 'sorrow—sorrow': 197, 'nameless': 198, 'evermore': 199, 'silken': 200, 'uncertain': 201, 'rustling': 202, 'purple': 203, 'curtain': 204, 'thrilled': 205, 'me—filled': 206, 'fantastic': 207, 'terrors': 208, 'felt': 209, 'beating': 210, 'repeating': 211, 'late': 212, 'presently': 213, 'stronger': 214, 'hesitating': 215, 'longer': 216, 'sir': 217, 'madam': 218, 'your': 219, 'forgiveness': 220, 'fact': 221, 'faintly': 222, 'scarce': 223, 'you—here': 224, 'opened': 225, 'wide': 226, 'deep': 227, 'peering': 228, 'long': 229, 'wondering': 230, 'fearing': 231, 'doubting': 232, 'dreams': 233, 'mortal': 234, 'dared': 235, 'dream': 236, 'silence': 237, 'gave': 238, 'echo': 239, 'murmured': 240, 'merely': 241, 'turning': 242, 'burning': 243, 'soon': 244, 'again': 245, 'somewhat': 246, 'louder': 247, 'something': 248, 'window': 249, 'lattice': 250, 'see': 251, 'thereat': 252, 'explore—': 253, 'moment': 254, 'explore': 255, 'wind': 256, 'open': 257, 'flung': 258, 'shutter': 259, 'when': 260, 'flirt': 261, 'flutter': 262, 'stepped': 263, 'stately': 264, 'saintly': 265, 'days': 266, 'least': 267, 'obeisance': 268, 'made': 269, 'minute': 270, 'stopped': 271, 'stayed': 272, 'mien': 273, 'lord': 274, 'lady': 275, 'ebony': 276, 'grave': 277, 'stern': 278, 'decorum': 279, 'countenance': 280, 'wore': 281, 'crest': 282, 'shorn': 283, 'shaven': 284, 'thou': 285, 'art': 286, 'craven': 287, 'ancient': 288, 'wandering': 289, 'nightly': 290, 'shore—': 291, 'lordly': 292, 'much': 293, 'marvelled': 294, 'hear': 295, 'discourse': 296, 'plainly': 297, 'answer': 298, 'little': 299, 'meaning—little': 300, 'relevancy': 301, 'cannot': 302, 'help': 303, 'agreeing': 304, 'living': 305, 'human': 306, 'being': 307, 'blessed': 308, 'seeing': 309, 'beast': 310, 'sculptured': 311, 'such': 312, 'lonely': 313, 'placid': 314, 'spoke': 315, 'did': 316, 'outpour': 317, 'farther': 318, 'uttered—not': 319, 'feather': 320, 'fluttered—': 321, 'scarcely': 322, 'other': 323, 'friends': 324, 'before—': 325, 'will': 326, 'hopes': 327, 'startled': 328, 'broken': 329, 'reply': 330, 'aptly': 331, 'doubtless': 332, 'utters': 333, 'stock': 334, 'store': 335, 'caught': 336, 'unhappy': 337, 'master': 338, 'unmerciful': 339, 'disaster': 340, 'fast': 341, 'faster': 342, 'songs': 343, 'bore—': 344, 'dirges': 345, 'hope': 346, 'melancholy': 347, '‘never—nevermore’': 348, 'straight': 349, 'wheeled': 350, 'cushioned': 351, 'seat': 352, 'front': 353, 'sinking': 354, 'betook': 355, 'myself': 356, 'linking': 357, 'unto': 358, 'thinking': 359, 'yore—': 360, 'gaunt': 361, 'meant': 362, 'croaking': 363, 'engaged': 364, 'guessing': 365, 'syllable': 366, 'expressing': 367, 'fiery': 368, 'burned': 369, 'bosom’s': 370, 'core': 371, 'divining': 372, 'head': 373, 'ease': 374, 'reclining': 375, 'cushion’s': 376, 'gloated': 377, 'violet': 378, 'gloating': 379, 'she': 380, 'press': 381, 'methought': 382, 'air': 383, 'denser': 384, 'perfumed': 385, 'unseen': 386, 'censer': 387, 'swung': 388, 'seraphim': 389, 'foot': 390, 'falls': 391, 'tinkled': 392, 'tufted': 393, 'wretch': 394, 'cried': 395, 'lent': 396, 'thee—by': 397, 'these': 398, 'respite—respite': 399, 'memories': 400, 'oh': 401, 'kind': 402, 'forget': 403, 'tempter': 404, 'tossed': 405, 'ashore': 406, 'desolate': 407, 'undaunted': 408, 'desert': 409, 'land': 410, 'enchanted—': 411, 'home': 412, 'horror': 413, 'haunted—tell': 414, 'implore—': 415, 'there—is': 416, 'balm': 417, 'gilead': 418, '—tell': 419, 'me—tell': 420, 'heaven': 421, 'bends': 422, 'us—by': 423, 'both': 424, 'adore—': 425, 'sorrow': 426, 'laden': 427, 'distant': 428, 'aidenn': 429, 'sainted': 430, 'our': 431, 'sign': 432, 'parting': 433, 'fiend': 434, 'shrieked': 435, 'upstarting—': 436, 'get': 437, 'black': 438, 'plume': 439, 'lie': 440, 'loneliness': 441, '—quit': 442, 'beak': 443, 'form': 444, 'off': 445, 'flitting': 446, 'pallid': 447, 'seeming': 448, 'demon’s': 449, 'him': 450, 'streaming': 451, 'throws': 452, 'lies': 453, 'floating': 454, 'lifted—nevermore': 455}\n",
            "456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnrwQd27Bwae"
      },
      "source": [
        "# Create Training Data\n",
        "\n",
        "This will split the input text into input sequences. It does it by breaking it into n-grams.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# created categorigal on-hot encoding labels\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b4971e04-e256-47a0-c257-86ce266a98f6"
      },
      "source": [
        "print(tokenizer.word_index['once'])\n",
        "print(tokenizer.word_index['upon'])\n",
        "print(tokenizer.word_index['a'])\n",
        "print(tokenizer.word_index['midnight'])\n",
        "print(tokenizer.word_index['dreary'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164\n",
            "40\n",
            "8\n",
            "165\n",
            "166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8583a0bd-2cc2-413a-b225-622d73ff4480"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0 164  40   8 165 166  88   3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-jwvfgbEF8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a291a799-776f-42ad-d4de-a2284c6759ee"
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtzlUMYadhKt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "29bfaf42-c56b-41bb-fa25-16e20f2b1c6b"
      },
      "source": [
        "print(f'Input: {input_sequences[5]}')\n",
        "print(f'xs:    {xs[5]}')\n",
        "print(f'label: {labels[5]}')\n",
        "print(f'ys:\\n{ys[5]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: [  0   0   0   0   0   0   0   0 164  40   8 165 166  88   3]\n",
            "xs:    [  0   0   0   0   0   0   0   0 164  40   8 165 166  88]\n",
            "label: 3\n",
            "ys:\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c6771aa6-9632-4028-a03b-c27149b9a4a6"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'i': 3, 'my': 4, 'of': 5, 'this': 6, 'that': 7, 'a': 8, 'chamber': 9, 'is': 10, 'raven': 11, 'bird': 12, 'on': 13, 'door': 14, 'nevermore': 15, 'at': 16, 'more': 17, 'from': 18, 'with': 19, 'then': 20, 'or': 21, 'nothing': 22, 'in': 23, 'me': 24, 'still': 25, 'no': 26, 'said': 27, 'but': 28, 'he': 29, 'above': 30, 'thy': 31, 'his': 32, 'there': 33, 'was': 34, 'to': 35, 'soul': 36, 'into': 37, 'word': 38, 'bust': 39, 'upon': 40, 'tapping': 41, 'as': 42, 'some': 43, 'door—': 44, 'it': 45, 'name': 46, 'so': 47, '—': 48, 'lenore': 49, 'what': 50, 'by': 51, 'quoth': 52, 'one': 53, 'only': 54, 'floor': 55, 'for': 56, 'whom': 57, 'angels': 58, 'before': 59, 'all': 60, 'be': 61, 'fancy': 62, 'if': 63, 'came': 64, 'rapping': 65, 'visitor': 66, 'its': 67, 'lenore—': 68, 'maiden': 69, 'here': 70, 'heart': 71, 'spoken': 72, 'back': 73, 'perched': 74, 'sat': 75, 'sitting': 76, 'till': 77, 'have': 78, 'leave': 79, 'velvet': 80, 'whose': 81, 'lamp': 82, 'light': 83, 'o’er': 84, 'shall': 85, 'hath': 86, 'thee': 87, 'while': 88, 'many': 89, 'napping': 90, 'gently': 91, 'muttered': 92, 'ah': 93, 'each': 94, 'morrow': 95, 'lost': 96, 'rare': 97, 'radiant': 98, 'sad': 99, 'never': 100, 'now': 101, 'stood': 102, '’tis': 103, 'entreating': 104, 'entrance': 105, 'grew': 106, 'truly': 107, 'implore': 108, 'you': 109, 'sure': 110, 'heard': 111, 'darkness': 112, 'dreaming': 113, 'ever': 114, 'unbroken': 115, 'stillness': 116, 'token': 117, 'whispered': 118, 'an': 119, 'within': 120, 'than': 121, 'surely': 122, 'let': 123, 'mystery': 124, 'yore': 125, 'not': 126, 'pallas': 127, 'just': 128, 'beguiling': 129, 'smiling': 130, 'though': 131, 'ghastly': 132, 'grim': 133, 'tell': 134, 'night’s': 135, 'plutonian': 136, 'shore': 137, 'ungainly': 138, 'fowl': 139, 'bore': 140, 'we': 141, 'yet': 142, 'flown': 143, 'followed': 144, 'burden': 145, 'ominous': 146, 'eyes': 147, 'lining': 148, 'god': 149, 'sent': 150, 'nepenthe': 151, 'quaff': 152, 'prophet': 153, 'thing': 154, 'evil': 155, '—prophet': 156, 'devil': 157, 'whether': 158, 'tempest': 159, 'clasp': 160, 'take': 161, 'out': 162, 'shadow': 163, 'once': 164, 'midnight': 165, 'dreary': 166, 'pondered': 167, 'weak': 168, 'weary': 169, 'over': 170, 'quaint': 171, 'curious': 172, 'volume': 173, 'forgotten': 174, 'lore—': 175, 'nodded': 176, 'nearly': 177, 'suddenly': 178, 'tis': 179, 'distinctly': 180, 'remember': 181, 'bleak': 182, 'december': 183, 'separate': 184, 'dying': 185, 'ember': 186, 'wrought': 187, 'ghost': 188, 'eagerly': 189, 'wished': 190, '—vainly': 191, 'had': 192, 'sought': 193, 'borrow': 194, 'books': 195, 'surcease': 196, 'sorrow—sorrow': 197, 'nameless': 198, 'evermore': 199, 'silken': 200, 'uncertain': 201, 'rustling': 202, 'purple': 203, 'curtain': 204, 'thrilled': 205, 'me—filled': 206, 'fantastic': 207, 'terrors': 208, 'felt': 209, 'beating': 210, 'repeating': 211, 'late': 212, 'presently': 213, 'stronger': 214, 'hesitating': 215, 'longer': 216, 'sir': 217, 'madam': 218, 'your': 219, 'forgiveness': 220, 'fact': 221, 'faintly': 222, 'scarce': 223, 'you—here': 224, 'opened': 225, 'wide': 226, 'deep': 227, 'peering': 228, 'long': 229, 'wondering': 230, 'fearing': 231, 'doubting': 232, 'dreams': 233, 'mortal': 234, 'dared': 235, 'dream': 236, 'silence': 237, 'gave': 238, 'echo': 239, 'murmured': 240, 'merely': 241, 'turning': 242, 'burning': 243, 'soon': 244, 'again': 245, 'somewhat': 246, 'louder': 247, 'something': 248, 'window': 249, 'lattice': 250, 'see': 251, 'thereat': 252, 'explore—': 253, 'moment': 254, 'explore': 255, 'wind': 256, 'open': 257, 'flung': 258, 'shutter': 259, 'when': 260, 'flirt': 261, 'flutter': 262, 'stepped': 263, 'stately': 264, 'saintly': 265, 'days': 266, 'least': 267, 'obeisance': 268, 'made': 269, 'minute': 270, 'stopped': 271, 'stayed': 272, 'mien': 273, 'lord': 274, 'lady': 275, 'ebony': 276, 'grave': 277, 'stern': 278, 'decorum': 279, 'countenance': 280, 'wore': 281, 'crest': 282, 'shorn': 283, 'shaven': 284, 'thou': 285, 'art': 286, 'craven': 287, 'ancient': 288, 'wandering': 289, 'nightly': 290, 'shore—': 291, 'lordly': 292, 'much': 293, 'marvelled': 294, 'hear': 295, 'discourse': 296, 'plainly': 297, 'answer': 298, 'little': 299, 'meaning—little': 300, 'relevancy': 301, 'cannot': 302, 'help': 303, 'agreeing': 304, 'living': 305, 'human': 306, 'being': 307, 'blessed': 308, 'seeing': 309, 'beast': 310, 'sculptured': 311, 'such': 312, 'lonely': 313, 'placid': 314, 'spoke': 315, 'did': 316, 'outpour': 317, 'farther': 318, 'uttered—not': 319, 'feather': 320, 'fluttered—': 321, 'scarcely': 322, 'other': 323, 'friends': 324, 'before—': 325, 'will': 326, 'hopes': 327, 'startled': 328, 'broken': 329, 'reply': 330, 'aptly': 331, 'doubtless': 332, 'utters': 333, 'stock': 334, 'store': 335, 'caught': 336, 'unhappy': 337, 'master': 338, 'unmerciful': 339, 'disaster': 340, 'fast': 341, 'faster': 342, 'songs': 343, 'bore—': 344, 'dirges': 345, 'hope': 346, 'melancholy': 347, '‘never—nevermore’': 348, 'straight': 349, 'wheeled': 350, 'cushioned': 351, 'seat': 352, 'front': 353, 'sinking': 354, 'betook': 355, 'myself': 356, 'linking': 357, 'unto': 358, 'thinking': 359, 'yore—': 360, 'gaunt': 361, 'meant': 362, 'croaking': 363, 'engaged': 364, 'guessing': 365, 'syllable': 366, 'expressing': 367, 'fiery': 368, 'burned': 369, 'bosom’s': 370, 'core': 371, 'divining': 372, 'head': 373, 'ease': 374, 'reclining': 375, 'cushion’s': 376, 'gloated': 377, 'violet': 378, 'gloating': 379, 'she': 380, 'press': 381, 'methought': 382, 'air': 383, 'denser': 384, 'perfumed': 385, 'unseen': 386, 'censer': 387, 'swung': 388, 'seraphim': 389, 'foot': 390, 'falls': 391, 'tinkled': 392, 'tufted': 393, 'wretch': 394, 'cried': 395, 'lent': 396, 'thee—by': 397, 'these': 398, 'respite—respite': 399, 'memories': 400, 'oh': 401, 'kind': 402, 'forget': 403, 'tempter': 404, 'tossed': 405, 'ashore': 406, 'desolate': 407, 'undaunted': 408, 'desert': 409, 'land': 410, 'enchanted—': 411, 'home': 412, 'horror': 413, 'haunted—tell': 414, 'implore—': 415, 'there—is': 416, 'balm': 417, 'gilead': 418, '—tell': 419, 'me—tell': 420, 'heaven': 421, 'bends': 422, 'us—by': 423, 'both': 424, 'adore—': 425, 'sorrow': 426, 'laden': 427, 'distant': 428, 'aidenn': 429, 'sainted': 430, 'our': 431, 'sign': 432, 'parting': 433, 'fiend': 434, 'shrieked': 435, 'upstarting—': 436, 'get': 437, 'black': 438, 'plume': 439, 'lie': 440, 'loneliness': 441, '—quit': 442, 'beak': 443, 'form': 444, 'off': 445, 'flitting': 446, 'pallid': 447, 'seeming': 448, 'demon’s': 449, 'him': 450, 'streaming': 451, 'throws': 452, 'lies': 453, 'floating': 454, 'lifted—nevermore': 455}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hh40g6CBrX4"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fbf9672-620c-477a-b622-c4a26293e3b2"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 6.1110 - accuracy: 0.0277\n",
            "Epoch 2/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.8881 - accuracy: 0.0308\n",
            "Epoch 3/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.5630 - accuracy: 0.0575\n",
            "Epoch 4/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.4903 - accuracy: 0.0575\n",
            "Epoch 5/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.4546 - accuracy: 0.0575\n",
            "Epoch 6/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.4134 - accuracy: 0.0575\n",
            "Epoch 7/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.3639 - accuracy: 0.0575\n",
            "Epoch 8/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.2942 - accuracy: 0.0575\n",
            "Epoch 9/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.2226 - accuracy: 0.0575\n",
            "Epoch 10/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 5.1511 - accuracy: 0.0616\n",
            "Epoch 11/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.0864 - accuracy: 0.0616\n",
            "Epoch 12/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 5.0340 - accuracy: 0.0626\n",
            "Epoch 13/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.9810 - accuracy: 0.0637\n",
            "Epoch 14/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 4.9267 - accuracy: 0.0647\n",
            "Epoch 15/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.8769 - accuracy: 0.0637\n",
            "Epoch 16/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.8169 - accuracy: 0.0667\n",
            "Epoch 17/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.7664 - accuracy: 0.0760\n",
            "Epoch 18/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.7092 - accuracy: 0.0729\n",
            "Epoch 19/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.6642 - accuracy: 0.0852\n",
            "Epoch 20/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.6094 - accuracy: 0.0903\n",
            "Epoch 21/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.5412 - accuracy: 0.0996\n",
            "Epoch 22/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 4.4881 - accuracy: 0.0975\n",
            "Epoch 23/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.4385 - accuracy: 0.1027\n",
            "Epoch 24/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.3858 - accuracy: 0.1006\n",
            "Epoch 25/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.3245 - accuracy: 0.1170\n",
            "Epoch 26/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.2752 - accuracy: 0.1232\n",
            "Epoch 27/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.2254 - accuracy: 0.1294\n",
            "Epoch 28/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.1640 - accuracy: 0.1468\n",
            "Epoch 29/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.1270 - accuracy: 0.1622\n",
            "Epoch 30/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.0841 - accuracy: 0.1571\n",
            "Epoch 31/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 4.0311 - accuracy: 0.1725\n",
            "Epoch 32/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.9804 - accuracy: 0.1725\n",
            "Epoch 33/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 3.9369 - accuracy: 0.1756\n",
            "Epoch 34/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.8914 - accuracy: 0.1889\n",
            "Epoch 35/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.8410 - accuracy: 0.1982\n",
            "Epoch 36/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.8007 - accuracy: 0.2094\n",
            "Epoch 37/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 3.7583 - accuracy: 0.2115\n",
            "Epoch 38/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.7114 - accuracy: 0.2197\n",
            "Epoch 39/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 3.6673 - accuracy: 0.2341\n",
            "Epoch 40/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.6195 - accuracy: 0.2392\n",
            "Epoch 41/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.5740 - accuracy: 0.2444\n",
            "Epoch 42/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 3.5356 - accuracy: 0.2515\n",
            "Epoch 43/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.4884 - accuracy: 0.2587\n",
            "Epoch 44/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.4548 - accuracy: 0.2659\n",
            "Epoch 45/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 3.4209 - accuracy: 0.2669\n",
            "Epoch 46/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.3765 - accuracy: 0.2803\n",
            "Epoch 47/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 3.3372 - accuracy: 0.2895\n",
            "Epoch 48/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 3.2988 - accuracy: 0.2936\n",
            "Epoch 49/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.2679 - accuracy: 0.2885\n",
            "Epoch 50/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.2322 - accuracy: 0.3070\n",
            "Epoch 51/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.1964 - accuracy: 0.3142\n",
            "Epoch 52/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.1628 - accuracy: 0.3255\n",
            "Epoch 53/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.1310 - accuracy: 0.3214\n",
            "Epoch 54/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.0978 - accuracy: 0.3419\n",
            "Epoch 55/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.0591 - accuracy: 0.3419\n",
            "Epoch 56/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 3.0228 - accuracy: 0.3593\n",
            "Epoch 57/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.9897 - accuracy: 0.3604\n",
            "Epoch 58/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 2.9578 - accuracy: 0.3789\n",
            "Epoch 59/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.9294 - accuracy: 0.3768\n",
            "Epoch 60/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.9010 - accuracy: 0.3963\n",
            "Epoch 61/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.8738 - accuracy: 0.4014\n",
            "Epoch 62/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.8471 - accuracy: 0.4097\n",
            "Epoch 63/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 2.8266 - accuracy: 0.4117\n",
            "Epoch 64/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 2.7860 - accuracy: 0.4148\n",
            "Epoch 65/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.7552 - accuracy: 0.4251\n",
            "Epoch 66/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.7266 - accuracy: 0.4507\n",
            "Epoch 67/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.6982 - accuracy: 0.4384\n",
            "Epoch 68/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.6727 - accuracy: 0.4548\n",
            "Epoch 69/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.6538 - accuracy: 0.4692\n",
            "Epoch 70/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 2.6350 - accuracy: 0.4702\n",
            "Epoch 71/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.6020 - accuracy: 0.4805\n",
            "Epoch 72/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.5817 - accuracy: 0.4774\n",
            "Epoch 73/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 2.5429 - accuracy: 0.4949\n",
            "Epoch 74/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.5036 - accuracy: 0.5000\n",
            "Epoch 75/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.4666 - accuracy: 0.5082\n",
            "Epoch 76/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.4316 - accuracy: 0.5154\n",
            "Epoch 77/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.4105 - accuracy: 0.5318\n",
            "Epoch 78/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.3849 - accuracy: 0.5441\n",
            "Epoch 79/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.3593 - accuracy: 0.5411\n",
            "Epoch 80/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.3417 - accuracy: 0.5400\n",
            "Epoch 81/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.3104 - accuracy: 0.5524\n",
            "Epoch 82/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.2839 - accuracy: 0.5544\n",
            "Epoch 83/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.2585 - accuracy: 0.5678\n",
            "Epoch 84/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.2417 - accuracy: 0.5657\n",
            "Epoch 85/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.2132 - accuracy: 0.5698\n",
            "Epoch 86/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.2063 - accuracy: 0.5719\n",
            "Epoch 87/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.1865 - accuracy: 0.5749\n",
            "Epoch 88/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.1478 - accuracy: 0.5914\n",
            "Epoch 89/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.1215 - accuracy: 0.5914\n",
            "Epoch 90/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.0920 - accuracy: 0.6016\n",
            "Epoch 91/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.0773 - accuracy: 0.6129\n",
            "Epoch 92/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.0504 - accuracy: 0.6222\n",
            "Epoch 93/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.0352 - accuracy: 0.6232\n",
            "Epoch 94/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.0023 - accuracy: 0.6283\n",
            "Epoch 95/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.9882 - accuracy: 0.6376\n",
            "Epoch 96/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.9711 - accuracy: 0.6437\n",
            "Epoch 97/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.9477 - accuracy: 0.6509\n",
            "Epoch 98/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.9462 - accuracy: 0.6386\n",
            "Epoch 99/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.9097 - accuracy: 0.6478\n",
            "Epoch 100/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.8789 - accuracy: 0.6540\n",
            "Epoch 101/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.8523 - accuracy: 0.6756\n",
            "Epoch 102/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.8364 - accuracy: 0.6653\n",
            "Epoch 103/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.8114 - accuracy: 0.6704\n",
            "Epoch 104/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7890 - accuracy: 0.6940\n",
            "Epoch 105/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7778 - accuracy: 0.6807\n",
            "Epoch 106/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7587 - accuracy: 0.6797\n",
            "Epoch 107/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7377 - accuracy: 0.6879\n",
            "Epoch 108/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7158 - accuracy: 0.6982\n",
            "Epoch 109/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.7002 - accuracy: 0.6930\n",
            "Epoch 110/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.6901 - accuracy: 0.7115\n",
            "Epoch 111/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.6562 - accuracy: 0.7094\n",
            "Epoch 112/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.6327 - accuracy: 0.7166\n",
            "Epoch 113/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.6184 - accuracy: 0.7177\n",
            "Epoch 114/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.6003 - accuracy: 0.7218\n",
            "Epoch 115/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.5835 - accuracy: 0.7187\n",
            "Epoch 116/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.5896 - accuracy: 0.7197\n",
            "Epoch 117/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.5701 - accuracy: 0.7218\n",
            "Epoch 118/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.5378 - accuracy: 0.7361\n",
            "Epoch 119/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.5188 - accuracy: 0.7331\n",
            "Epoch 120/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4957 - accuracy: 0.7444\n",
            "Epoch 121/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4862 - accuracy: 0.7454\n",
            "Epoch 122/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4677 - accuracy: 0.7546\n",
            "Epoch 123/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4446 - accuracy: 0.7608\n",
            "Epoch 124/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4155 - accuracy: 0.7752\n",
            "Epoch 125/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.4070 - accuracy: 0.7710\n",
            "Epoch 126/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.3917 - accuracy: 0.7762\n",
            "Epoch 127/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3762 - accuracy: 0.7782\n",
            "Epoch 128/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3650 - accuracy: 0.7834\n",
            "Epoch 129/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3479 - accuracy: 0.7864\n",
            "Epoch 130/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3324 - accuracy: 0.7936\n",
            "Epoch 131/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3236 - accuracy: 0.7967\n",
            "Epoch 132/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.3060 - accuracy: 0.7988\n",
            "Epoch 133/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2852 - accuracy: 0.8029\n",
            "Epoch 134/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2698 - accuracy: 0.8008\n",
            "Epoch 135/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2545 - accuracy: 0.8018\n",
            "Epoch 136/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2467 - accuracy: 0.8018\n",
            "Epoch 137/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2427 - accuracy: 0.8049\n",
            "Epoch 138/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.2194 - accuracy: 0.8070\n",
            "Epoch 139/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.1947 - accuracy: 0.8224\n",
            "Epoch 140/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.1747 - accuracy: 0.8234\n",
            "Epoch 141/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.1625 - accuracy: 0.8214\n",
            "Epoch 142/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.1490 - accuracy: 0.8214\n",
            "Epoch 143/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.1342 - accuracy: 0.8172\n",
            "Epoch 144/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.1211 - accuracy: 0.8296\n",
            "Epoch 145/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.1052 - accuracy: 0.8244\n",
            "Epoch 146/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.0905 - accuracy: 0.8296\n",
            "Epoch 147/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.0801 - accuracy: 0.8347\n",
            "Epoch 148/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0873 - accuracy: 0.8316\n",
            "Epoch 149/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0864 - accuracy: 0.8409\n",
            "Epoch 150/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.0863 - accuracy: 0.8265\n",
            "Epoch 151/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.0778 - accuracy: 0.8275\n",
            "Epoch 152/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0693 - accuracy: 0.8275\n",
            "Epoch 153/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0588 - accuracy: 0.8275\n",
            "Epoch 154/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0337 - accuracy: 0.8316\n",
            "Epoch 155/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0156 - accuracy: 0.8450\n",
            "Epoch 156/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 1.0076 - accuracy: 0.8419\n",
            "Epoch 157/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9902 - accuracy: 0.8450\n",
            "Epoch 158/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9737 - accuracy: 0.8491\n",
            "Epoch 159/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9564 - accuracy: 0.8511\n",
            "Epoch 160/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.9475 - accuracy: 0.8583\n",
            "Epoch 161/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9444 - accuracy: 0.8563\n",
            "Epoch 162/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.9318 - accuracy: 0.8583\n",
            "Epoch 163/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9230 - accuracy: 0.8563\n",
            "Epoch 164/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.9036 - accuracy: 0.8593\n",
            "Epoch 165/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.8932 - accuracy: 0.8604\n",
            "Epoch 166/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8830 - accuracy: 0.8645\n",
            "Epoch 167/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8764 - accuracy: 0.8696\n",
            "Epoch 168/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8739 - accuracy: 0.8655\n",
            "Epoch 169/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8626 - accuracy: 0.8665\n",
            "Epoch 170/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.8524 - accuracy: 0.8717\n",
            "Epoch 171/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8445 - accuracy: 0.8727\n",
            "Epoch 172/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8438 - accuracy: 0.8686\n",
            "Epoch 173/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8295 - accuracy: 0.8758\n",
            "Epoch 174/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8196 - accuracy: 0.8717\n",
            "Epoch 175/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8330 - accuracy: 0.8686\n",
            "Epoch 176/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.8060 - accuracy: 0.8789\n",
            "Epoch 177/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7985 - accuracy: 0.8727\n",
            "Epoch 178/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7877 - accuracy: 0.8830\n",
            "Epoch 179/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7851 - accuracy: 0.8778\n",
            "Epoch 180/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7840 - accuracy: 0.8768\n",
            "Epoch 181/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7695 - accuracy: 0.8809\n",
            "Epoch 182/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7536 - accuracy: 0.8809\n",
            "Epoch 183/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7360 - accuracy: 0.8912\n",
            "Epoch 184/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7344 - accuracy: 0.8881\n",
            "Epoch 185/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7336 - accuracy: 0.8860\n",
            "Epoch 186/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7279 - accuracy: 0.8881\n",
            "Epoch 187/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.7412 - accuracy: 0.8778\n",
            "Epoch 188/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.7215 - accuracy: 0.8881\n",
            "Epoch 189/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7123 - accuracy: 0.8891\n",
            "Epoch 190/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7125 - accuracy: 0.8840\n",
            "Epoch 191/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7270 - accuracy: 0.8860\n",
            "Epoch 192/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.7294 - accuracy: 0.8737\n",
            "Epoch 193/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.8912\n",
            "Epoch 194/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.8973\n",
            "Epoch 195/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6616 - accuracy: 0.8963\n",
            "Epoch 196/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6513 - accuracy: 0.8984\n",
            "Epoch 197/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6505 - accuracy: 0.8973\n",
            "Epoch 198/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6401 - accuracy: 0.9025\n",
            "Epoch 199/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6312 - accuracy: 0.9076\n",
            "Epoch 200/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6205 - accuracy: 0.9055\n",
            "Epoch 201/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6122 - accuracy: 0.9055\n",
            "Epoch 202/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.9086\n",
            "Epoch 203/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5981 - accuracy: 0.9086\n",
            "Epoch 204/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5933 - accuracy: 0.9076\n",
            "Epoch 205/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5942 - accuracy: 0.9055\n",
            "Epoch 206/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6008 - accuracy: 0.9066\n",
            "Epoch 207/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.6247 - accuracy: 0.8984\n",
            "Epoch 208/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.6133 - accuracy: 0.9045\n",
            "Epoch 209/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.9045\n",
            "Epoch 210/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5830 - accuracy: 0.9045\n",
            "Epoch 211/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5660 - accuracy: 0.9127\n",
            "Epoch 212/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5615 - accuracy: 0.9097\n",
            "Epoch 213/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.9168\n",
            "Epoch 214/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.9127\n",
            "Epoch 215/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.9127\n",
            "Epoch 216/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.9138\n",
            "Epoch 217/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.9138\n",
            "Epoch 218/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.9179\n",
            "Epoch 219/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.9179\n",
            "Epoch 220/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.9240\n",
            "Epoch 221/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.9230\n",
            "Epoch 222/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.9209\n",
            "Epoch 223/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.9199\n",
            "Epoch 224/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.9117\n",
            "Epoch 225/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.9199\n",
            "Epoch 226/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.9209\n",
            "Epoch 227/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.9199\n",
            "Epoch 228/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.9168\n",
            "Epoch 229/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5212 - accuracy: 0.9076\n",
            "Epoch 230/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.9045\n",
            "Epoch 231/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.9127\n",
            "Epoch 232/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.9117\n",
            "Epoch 233/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.9199\n",
            "Epoch 234/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.9179\n",
            "Epoch 235/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.9261\n",
            "Epoch 236/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.9302\n",
            "Epoch 237/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.9240\n",
            "Epoch 238/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9261\n",
            "Epoch 239/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.9292\n",
            "Epoch 240/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.9302\n",
            "Epoch 241/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.9302\n",
            "Epoch 242/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.9333\n",
            "Epoch 243/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.9322\n",
            "Epoch 244/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.9322\n",
            "Epoch 245/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.9333\n",
            "Epoch 246/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.9363\n",
            "Epoch 247/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.9322\n",
            "Epoch 248/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.9363\n",
            "Epoch 249/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.9384\n",
            "Epoch 250/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3815 - accuracy: 0.9374\n",
            "Epoch 251/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.9353\n",
            "Epoch 252/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.9353\n",
            "Epoch 253/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.9353\n",
            "Epoch 254/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.9363\n",
            "Epoch 255/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3684 - accuracy: 0.9363\n",
            "Epoch 256/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3650 - accuracy: 0.9363\n",
            "Epoch 257/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.9374\n",
            "Epoch 258/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.9312\n",
            "Epoch 259/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.9343\n",
            "Epoch 260/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.9343\n",
            "Epoch 261/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.9333\n",
            "Epoch 262/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.9271\n",
            "Epoch 263/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.9343\n",
            "Epoch 264/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.9251\n",
            "Epoch 265/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.9240\n",
            "Epoch 266/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.9312\n",
            "Epoch 267/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.9343\n",
            "Epoch 268/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.9374\n",
            "Epoch 269/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.9384\n",
            "Epoch 270/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.9374\n",
            "Epoch 271/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.9405\n",
            "Epoch 272/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.9343\n",
            "Epoch 273/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.9312\n",
            "Epoch 274/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.9271\n",
            "Epoch 275/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3434 - accuracy: 0.9353\n",
            "Epoch 276/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.9405\n",
            "Epoch 277/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.3184 - accuracy: 0.9425\n",
            "Epoch 278/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.9446\n",
            "Epoch 279/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.9435\n",
            "Epoch 280/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2975 - accuracy: 0.9456\n",
            "Epoch 281/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2931 - accuracy: 0.9446\n",
            "Epoch 282/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2891 - accuracy: 0.9487\n",
            "Epoch 283/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2886 - accuracy: 0.9466\n",
            "Epoch 284/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2862 - accuracy: 0.9476\n",
            "Epoch 285/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2827 - accuracy: 0.9487\n",
            "Epoch 286/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2797 - accuracy: 0.9507\n",
            "Epoch 287/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.9476\n",
            "Epoch 288/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2776 - accuracy: 0.9517\n",
            "Epoch 289/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.9497\n",
            "Epoch 290/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.9394\n",
            "Epoch 291/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3224 - accuracy: 0.9374\n",
            "Epoch 292/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2993 - accuracy: 0.9435\n",
            "Epoch 293/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2887 - accuracy: 0.9425\n",
            "Epoch 294/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2793 - accuracy: 0.9456\n",
            "Epoch 295/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2777 - accuracy: 0.9507\n",
            "Epoch 296/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2696 - accuracy: 0.9528\n",
            "Epoch 297/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2691 - accuracy: 0.9538\n",
            "Epoch 298/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2620 - accuracy: 0.9559\n",
            "Epoch 299/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2564 - accuracy: 0.9538\n",
            "Epoch 300/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.9538\n",
            "Epoch 301/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2483 - accuracy: 0.9538\n",
            "Epoch 302/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2456 - accuracy: 0.9548\n",
            "Epoch 303/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2426 - accuracy: 0.9589\n",
            "Epoch 304/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2412 - accuracy: 0.9559\n",
            "Epoch 305/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2443 - accuracy: 0.9589\n",
            "Epoch 306/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2400 - accuracy: 0.9559\n",
            "Epoch 307/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2372 - accuracy: 0.9600\n",
            "Epoch 308/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2335 - accuracy: 0.9589\n",
            "Epoch 309/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2325 - accuracy: 0.9569\n",
            "Epoch 310/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2373 - accuracy: 0.9569\n",
            "Epoch 311/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.9538\n",
            "Epoch 312/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2483 - accuracy: 0.9528\n",
            "Epoch 313/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.9559\n",
            "Epoch 314/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2402 - accuracy: 0.9569\n",
            "Epoch 315/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2339 - accuracy: 0.9589\n",
            "Epoch 316/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.9589\n",
            "Epoch 317/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2371 - accuracy: 0.9569\n",
            "Epoch 318/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2299 - accuracy: 0.9579\n",
            "Epoch 319/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2232 - accuracy: 0.9579\n",
            "Epoch 320/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2391 - accuracy: 0.9487\n",
            "Epoch 321/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2503 - accuracy: 0.9476\n",
            "Epoch 322/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2559 - accuracy: 0.9466\n",
            "Epoch 323/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.9517\n",
            "Epoch 324/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2535 - accuracy: 0.9446\n",
            "Epoch 325/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.9476\n",
            "Epoch 326/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2726 - accuracy: 0.9435\n",
            "Epoch 327/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2693 - accuracy: 0.9435\n",
            "Epoch 328/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2645 - accuracy: 0.9466\n",
            "Epoch 329/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.9487\n",
            "Epoch 330/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2345 - accuracy: 0.9528\n",
            "Epoch 331/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2127 - accuracy: 0.9569\n",
            "Epoch 332/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2048 - accuracy: 0.9569\n",
            "Epoch 333/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2006 - accuracy: 0.9620\n",
            "Epoch 334/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1978 - accuracy: 0.9610\n",
            "Epoch 335/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9579\n",
            "Epoch 336/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1929 - accuracy: 0.9589\n",
            "Epoch 337/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1911 - accuracy: 0.9610\n",
            "Epoch 338/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1899 - accuracy: 0.9589\n",
            "Epoch 339/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1880 - accuracy: 0.9610\n",
            "Epoch 340/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9620\n",
            "Epoch 341/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.9569\n",
            "Epoch 342/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.9579\n",
            "Epoch 343/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.9600\n",
            "Epoch 344/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1827 - accuracy: 0.9600\n",
            "Epoch 345/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1818 - accuracy: 0.9559\n",
            "Epoch 346/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1809 - accuracy: 0.9569\n",
            "Epoch 347/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9579\n",
            "Epoch 348/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1846 - accuracy: 0.9548\n",
            "Epoch 349/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1775 - accuracy: 0.9610\n",
            "Epoch 350/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2172 - accuracy: 0.9446\n",
            "Epoch 351/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1901 - accuracy: 0.9559\n",
            "Epoch 352/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9579\n",
            "Epoch 353/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1787 - accuracy: 0.9589\n",
            "Epoch 354/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1766 - accuracy: 0.9600\n",
            "Epoch 355/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1730 - accuracy: 0.9620\n",
            "Epoch 356/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1703 - accuracy: 0.9579\n",
            "Epoch 357/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1676 - accuracy: 0.9610\n",
            "Epoch 358/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.9610\n",
            "Epoch 359/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.9641\n",
            "Epoch 360/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9630\n",
            "Epoch 361/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1623 - accuracy: 0.9600\n",
            "Epoch 362/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9610\n",
            "Epoch 363/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.1610 - accuracy: 0.9620\n",
            "Epoch 364/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1592 - accuracy: 0.9610\n",
            "Epoch 365/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9620\n",
            "Epoch 366/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9600\n",
            "Epoch 367/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1576 - accuracy: 0.9600\n",
            "Epoch 368/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1570 - accuracy: 0.9589\n",
            "Epoch 369/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1542 - accuracy: 0.9579\n",
            "Epoch 370/500\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.1528 - accuracy: 0.9630\n",
            "Epoch 371/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1527 - accuracy: 0.9579\n",
            "Epoch 372/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9600\n",
            "Epoch 373/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1509 - accuracy: 0.9610\n",
            "Epoch 374/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.9600\n",
            "Epoch 375/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9610\n",
            "Epoch 376/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1481 - accuracy: 0.9620\n",
            "Epoch 377/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1469 - accuracy: 0.9610\n",
            "Epoch 378/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.9589\n",
            "Epoch 379/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.9579\n",
            "Epoch 380/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.9630\n",
            "Epoch 381/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1487 - accuracy: 0.9620\n",
            "Epoch 382/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1510 - accuracy: 0.9610\n",
            "Epoch 383/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1719 - accuracy: 0.9476\n",
            "Epoch 384/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1832 - accuracy: 0.9517\n",
            "Epoch 385/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2053 - accuracy: 0.9425\n",
            "Epoch 386/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2431 - accuracy: 0.9384\n",
            "Epoch 387/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2230 - accuracy: 0.9507\n",
            "Epoch 388/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2645 - accuracy: 0.9343\n",
            "Epoch 389/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2307 - accuracy: 0.9487\n",
            "Epoch 390/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.2082 - accuracy: 0.9435\n",
            "Epoch 391/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 0.9538\n",
            "Epoch 392/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1751 - accuracy: 0.9538\n",
            "Epoch 393/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1801 - accuracy: 0.9569\n",
            "Epoch 394/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1749 - accuracy: 0.9600\n",
            "Epoch 395/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1626 - accuracy: 0.9589\n",
            "Epoch 396/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9630\n",
            "Epoch 397/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.9610\n",
            "Epoch 398/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.9641\n",
            "Epoch 399/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9641\n",
            "Epoch 400/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.9651\n",
            "Epoch 401/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.9600\n",
            "Epoch 402/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.9641\n",
            "Epoch 403/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9600\n",
            "Epoch 404/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1356 - accuracy: 0.9620\n",
            "Epoch 405/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.9651\n",
            "Epoch 406/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1335 - accuracy: 0.9620\n",
            "Epoch 407/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9600\n",
            "Epoch 408/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1310 - accuracy: 0.9620\n",
            "Epoch 409/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9600\n",
            "Epoch 410/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9610\n",
            "Epoch 411/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1356 - accuracy: 0.9641\n",
            "Epoch 412/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.9589\n",
            "Epoch 413/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.9579\n",
            "Epoch 414/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.9610\n",
            "Epoch 415/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.9651\n",
            "Epoch 416/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1298 - accuracy: 0.9630\n",
            "Epoch 417/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9610\n",
            "Epoch 418/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1276 - accuracy: 0.9600\n",
            "Epoch 419/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.9589\n",
            "Epoch 420/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9620\n",
            "Epoch 421/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1251 - accuracy: 0.9579\n",
            "Epoch 422/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1235 - accuracy: 0.9641\n",
            "Epoch 423/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.9610\n",
            "Epoch 424/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1226 - accuracy: 0.9610\n",
            "Epoch 425/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1262 - accuracy: 0.9569\n",
            "Epoch 426/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.9600\n",
            "Epoch 427/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1208 - accuracy: 0.9641\n",
            "Epoch 428/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 0.9620\n",
            "Epoch 429/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1216 - accuracy: 0.9589\n",
            "Epoch 430/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9620\n",
            "Epoch 431/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1193 - accuracy: 0.9600\n",
            "Epoch 432/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9610\n",
            "Epoch 433/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1174 - accuracy: 0.9641\n",
            "Epoch 434/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.9630\n",
            "Epoch 435/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1318 - accuracy: 0.9579\n",
            "Epoch 436/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.9517\n",
            "Epoch 437/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1756 - accuracy: 0.9487\n",
            "Epoch 438/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1523 - accuracy: 0.9579\n",
            "Epoch 439/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1350 - accuracy: 0.9589\n",
            "Epoch 440/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.9507\n",
            "Epoch 441/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1559 - accuracy: 0.9559\n",
            "Epoch 442/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.9579\n",
            "Epoch 443/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9600\n",
            "Epoch 444/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.9559\n",
            "Epoch 445/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9620\n",
            "Epoch 446/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9620\n",
            "Epoch 447/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.9528\n",
            "Epoch 448/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9641\n",
            "Epoch 449/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.9651\n",
            "Epoch 450/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9620\n",
            "Epoch 451/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1134 - accuracy: 0.9610\n",
            "Epoch 452/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9641\n",
            "Epoch 453/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9620\n",
            "Epoch 454/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9610\n",
            "Epoch 455/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1102 - accuracy: 0.9641\n",
            "Epoch 456/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9651\n",
            "Epoch 457/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9630\n",
            "Epoch 458/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9620\n",
            "Epoch 459/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1072 - accuracy: 0.9641\n",
            "Epoch 460/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1063 - accuracy: 0.9589\n",
            "Epoch 461/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1065 - accuracy: 0.9630\n",
            "Epoch 462/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1057 - accuracy: 0.9630\n",
            "Epoch 463/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.9579\n",
            "Epoch 464/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9610\n",
            "Epoch 465/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9600\n",
            "Epoch 466/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9641\n",
            "Epoch 467/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9630\n",
            "Epoch 468/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9620\n",
            "Epoch 469/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.9630\n",
            "Epoch 470/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.9620\n",
            "Epoch 471/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.9630\n",
            "Epoch 472/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9641\n",
            "Epoch 473/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 0.9589\n",
            "Epoch 474/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9630\n",
            "Epoch 475/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.9620\n",
            "Epoch 476/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1001 - accuracy: 0.9600\n",
            "Epoch 477/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9610\n",
            "Epoch 478/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1001 - accuracy: 0.9610\n",
            "Epoch 479/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0993 - accuracy: 0.9610\n",
            "Epoch 480/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9610\n",
            "Epoch 481/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1015 - accuracy: 0.9620\n",
            "Epoch 482/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9610\n",
            "Epoch 483/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1006 - accuracy: 0.9610\n",
            "Epoch 484/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1006 - accuracy: 0.9610\n",
            "Epoch 485/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.9610\n",
            "Epoch 486/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0993 - accuracy: 0.9641\n",
            "Epoch 487/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9630\n",
            "Epoch 488/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0981 - accuracy: 0.9620\n",
            "Epoch 489/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0969 - accuracy: 0.9610\n",
            "Epoch 490/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.9630\n",
            "Epoch 491/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0954 - accuracy: 0.9630\n",
            "Epoch 492/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9600\n",
            "Epoch 493/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0951 - accuracy: 0.9610\n",
            "Epoch 494/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0947 - accuracy: 0.9641\n",
            "Epoch 495/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.9589\n",
            "Epoch 496/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0949 - accuracy: 0.9600\n",
            "Epoch 497/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0936 - accuracy: 0.9630\n",
            "Epoch 498/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 0.9600\n",
            "Epoch 499/500\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9579\n",
            "Epoch 500/500\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 0.9620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "5023e96a-a7ac-43ab-be25-37e84337b8fa"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP6z5rLjBZi7"
      },
      "source": [
        "# Predict next words\n",
        "\n",
        "Now the following function uses the trained model to predict the following word taking as seed the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e0eab39-0e30-4370-b0e5-5ded9c944c12"
      },
      "source": [
        "seed_text = \"Quoth the raven\"\n",
        "next_words = 20\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quoth the raven nevermore nevermore beguiling all the tempest my sad hath sent thee door yore — yore — — violet —tell devil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYlZRvdPCiqS"
      },
      "source": [
        "# Experiment:\n",
        "\n",
        "Try running the previous cell with a higher number of next_words. What happens?\n",
        "\n",
        "This problem is caused due to our lack of a big training dataset. Remember, we are training our model with only one poem. That is far from being enough.\n",
        "\n",
        "One way to solve that would be using a much bigger dataset."
      ]
    }
  ]
}